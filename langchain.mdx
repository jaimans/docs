---
title: 'Langchain'
description: 'Use OpenSesame with Langchain'
---

OpenSesame can integrate directly into your langchain workflows with only a few lines of code

Step 1. Install the OpenSesame SDK:

<CodeGroup>

```bash python 
pip install opensesame-sdk
```

</CodeGroup>

Step 2. Set up the OpenSesame_langchain client and retrieve your custom callback_manager.

<CodeGroup>

```python 
from opensesame import OpenSesame_langchain

os_langchain = OpenSesame_langchain({
        'open_sesame_key': 'your_open_sesame_key',
        'project_name': 'your_project_name'
    })

my_callback_manager = os_langchain.rag_callback_manager()
```
</CodeGroup>

Step 3. Add the callback_manager to your Langchain chain.

Example 1: Using LLMChain

<CodeGroup>
```python 

# Build your chain as usual

llm = ChatOpenAI() # your Langchain LLM 

prompt = "User prompt"

chain =  llm | StrOutputParser() # Build your chain as usual

# Add in your OpenSesame Callback

response = chain.invoke(prompt, config={"callbacks": [my_callback_manager.handlers[0]]}) 

```

</CodeGroup>

Example 2: Using RetrievalQA

<CodeGroup>
```python 

# Build your chain as usual

llm = ChatOpenAI()  

embeddings = OpenAIEmbeddings() 

vectorstore = PineconeVectorStore(index_name=PINECONE_INDEX, embedding=embeddings, text_key="text", pinecone_api_key=PINECONE_API_KEY)

retriever = vectorstore.as_retriever()

# Set up a QA chain and add the OpenSesame callback_manager

chain = RetrievalQA.from_chain_type(llm=llm, chain_type="refine", retriever=retriever, callback_manager=my_callback_manager)

response = chain.invoke({"query": "How has AI evolved in the last decade?"})

```

</CodeGroup>

The call_back manager is used to send your requests to OpenSesame.
It can be added to any of your Langchain worflows. Agents will be handled seperately

